{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入所需要的机器学习库\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from ast import literal_eval\n",
    "from keras.preprocessing.image import img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 声明实验所需要的各项目录\n",
    "root_path = \"H:\\视频数据\"\n",
    "video_dir = \"video\"\n",
    "picture_dir = \"picture\"\n",
    "project_info = \"original_info.csv\"\n",
    "project_process_info = \"project_process_info.csv\"\n",
    "model_path = \"model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文件夹不存在创建文件夹\n",
    "def mkdir(path):\n",
    "    folder = os.path.exists(path)\n",
    "    if not folder:\n",
    "        os.makedirs(path)\n",
    "        print(\"Make new director.\")\n",
    "    else:\n",
    "        print(\"The director exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#视频转化为图片序列，每256帧裁图一张，最终将结果变量记录保存；后续也可以按照视频时长按比例截图\n",
    "video_path = root_path + \"/\" + video_dir\n",
    "seq_picture_path = root_path + \"/\" + picture_dir\n",
    "df = pd.read_csv(root_path + \"/\" + project_info, sep=',')\n",
    "result_df = []\n",
    "for index in df.index:\n",
    "    print(\"Load \" + str(index) + \"th video.\")\n",
    "    video_name = df.iloc[index][\"name\"].split(\".\")[0]\n",
    "    video_format = \"mp4\"\n",
    "    video_seq_path = seq_picture_path + \"/\" + video_name + \".mp4\"\n",
    "    mkdir(video_seq_path)\n",
    "    video_label = df.iloc[index][\"score\"]\n",
    "    video_seq_list = []\n",
    "    cap = cv2.VideoCapture(video_path + \"/\" + video_name + \".\" + video_format)\n",
    "    print(video_path + \"/\" + video_name + \".\" + video_format)\n",
    "    frame_num = 0\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        frame_num += 1\n",
    "        if ret == True:\n",
    "            if frame_num % 256 == 0:\n",
    "                print(\"Watch the \" + str(frame_num/256) + \" video\")\n",
    "                fram_path = video_seq_path + \"/\" + str(frame_num/256) + \".jpg\"\n",
    "                video_seq_list.append(fram_path)\n",
    "                cv2.imencode(\".jpg\", frame)[1].tofile(fram_path)\n",
    "            if cv2.waitKey(1)&0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    result_df.append((video_name, video_format, video_seq_list, video_label))\n",
    "result_pdf = pd.DataFrame(result_df, columns = [\"video_name\", \"video_format\", \"video_seq_list\", \"video_label\"])\n",
    "result_pdf.to_csv(root_path + \"/\" + project_process_info, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成训练模型所需的配置文件\n",
    "result_pdf = pd.DataFrame(result_df, columns = [\"video_name\", \"video_format\", \"video_seq_list\", \"video_label\"])\n",
    "result_pdf.to_csv(root_path + \"/\" + project_process_info, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取生成的配置文件\n",
    "seq_length = 64\n",
    "result_pdf = pd.read_csv(root_path + \"/\" + project_process_info)\n",
    "result_pdf['video_seq_list'] = result_pdf['video_seq_list'].apply(literal_eval)\n",
    "result_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像预处理\n",
    "def process_image(image, target_shape):\n",
    "    h, w, _  = target_shape\n",
    "    image = load_img(image, target_size=(h, w))\n",
    "    image_arr = img_to_array(image)\n",
    "    x = (image_arr/255.).astype(np.float32)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集乱序\n",
    "result_pdf = sklearn.utils.shuffle(result_pdf)\n",
    "result_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "train_result_pdf = result_pdf.iloc[:-50]\n",
    "test_result_pdf = result_pdf.iloc[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练数据转化为tensor\n",
    "video_seq_list = train_result_pdf[\"video_seq_list\"].values\n",
    "\n",
    "video_seq_array = list()\n",
    "for samples in video_seq_list:\n",
    "    sample_arrays = [process_image(x, (128,128,3)) for x in samples]\n",
    "    sample_arrays = np.array(sample_arrays)\n",
    "    if seq_length > len(sample_arrays):\n",
    "        try:\n",
    "            sample_arrays = np.concatenate([sample_arrays, np.zeros([seq_length-len(sample_arrays),128,128,3])], axis = 0)\n",
    "        except Exception:\n",
    "            print(\"Error \")\n",
    "            continue\n",
    "    else:\n",
    "        sample_arrays = sample_arrays[:seq_length,:,:,:]\n",
    "    print(sample_arrays.shape)\n",
    "    video_seq_array.append(sample_arrays)\n",
    "video_seq_array = np.array(video_seq_array)\n",
    "print(video_seq_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集label处理，当前视频分为四类\n",
    "labels = train_result_pdf[\"video_label\"].values\n",
    "one_hot_labels = np.zeros([labels.shape[0], 4])\n",
    "label_dict = {'A':0,'B':1,'C':2,'D':3}\n",
    "for index in range(len(labels)):\n",
    "    one_hot_labels[index][label_dict[labels[index]]] = 1\n",
    "one_hot_labels.shape\n",
    "one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "seq_length = 64\n",
    "image_size = 128\n",
    "channel = 3\n",
    "\n",
    "inputs = keras.Input(shape= (seq_length, image_size, image_size, channel))\n",
    "resnet50 = keras.applications.mobilenet_v2.MobileNetV2(input_shape=(128, 128, 3), weights='imagenet')\n",
    "\n",
    "# resnet50 = keras.applications.ResNet50(include_top=False, pooling = 'max', weights='imagenet')\n",
    "for layers in resnet50.layers[0:-2]:\n",
    "    layers.trainable = False\n",
    "\n",
    "cnn = keras.Model(inputs=resnet50.input, outputs=resnet50.output)\n",
    "encoded_frames = keras.layers.TimeDistributed(cnn)(inputs)\n",
    "encoded_sequence = keras.layers.LSTM(32)(encoded_frames)\n",
    "\n",
    "hidden_layers = keras.layers.Dense(64, activation =\"relu\")(encoded_sequence)\n",
    "outputs = keras.layers.Dense(4,activation=\"softmax\")(hidden_layers)\n",
    "model = keras.Model([inputs], outputs)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer=\"adam\", metrics= [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "hist = model.fit([video_seq_array],one_hot_labels, validation_split = 0.2, batch_size=10, verbose=1, epochs=30, shuffle=True)\n",
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试数据转化为tensor\n",
    "video_seq_list = test_result_pdf[\"video_seq_list\"].values\n",
    "\n",
    "video_seq_array = list()\n",
    "for samples in video_seq_list:\n",
    "    sample_arrays = [process_image(x, (128,128,3)) for x in samples]\n",
    "    sample_arrays = np.array(sample_arrays)\n",
    "    if seq_length > len(sample_arrays):\n",
    "        try:\n",
    "            sample_arrays = np.concatenate([sample_arrays, np.zeros([seq_length-len(sample_arrays),128,128,3])], axis = 0)\n",
    "        except Exception:\n",
    "            print(\"Error \")\n",
    "            continue\n",
    "    else:\n",
    "        sample_arrays = sample_arrays[:seq_length,:,:,:]\n",
    "    print(sample_arrays.shape)\n",
    "    video_seq_array.append(sample_arrays)\n",
    "video_seq_array = np.array(video_seq_array)\n",
    "print(video_seq_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集label处理\n",
    "labels = test_result_pdf[\"video_label\"].values\n",
    "one_hot_labels = np.zeros([labels.shape[0], 4])\n",
    "label_dict = {'A':0,'B':1,'C':2,'D':3}\n",
    "for index in range(len(labels)):\n",
    "    one_hot_labels[index][label_dict[labels[index]]] = 1\n",
    "one_hot_labels.shape\n",
    "one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型评价\n",
    "result = model.evaluate([video_seq_array],one_hot_labels, batch_size=10, verbose=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测\n",
    "result = model.predict([video_seq_array], batch_size=10, verbose=1)\n",
    "result_label = np.argmax(result, axis=1)\n",
    "result_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算平均得分误差\n",
    "label_dict = {'A':0,'B':1,'C':2,'D':3}\n",
    "convert_label = np.array([label_dict[item] for item in labels])\n",
    "np.mean(np.abs(convert_label - result_label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
